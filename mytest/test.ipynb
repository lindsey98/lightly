{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import lightly.models as models\n",
    "import lightly.loss as loss\n",
    "import lightly.data as data\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# for plotting\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.offsetbox as osb\n",
    "from matplotlib import rcParams as rcp\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# for resizing images to thumbnails\n",
    "import torchvision.transforms.functional as functional\n",
    "\n",
    "# for clustering and 2d representations\n",
    "from sklearn import random_projection\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# for logo2k and logo targetlist\n",
    "# train_list = [x.strip('\\n') for x in open('/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/train_targets.txt').readlines()]\n",
    "# test_list = [x.strip('\\n') for x in open('/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/test_targets.txt').readlines()]\n",
    "\n",
    "# os.makedirs('../datasets/targetlist/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/targetlist/test', exist_ok=True)\n",
    "\n",
    "# for data in train_list:\n",
    "#     if not os.path.exists(os.path.join('../datasets/targetlist/train/', data.split('/')[0])):\n",
    "#         os.makedirs('../datasets/targetlist/train/' + data.split('/')[0], exist_ok=True)\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('/home/l/liny/ruofan/PhishIntention/src/phishpedia/expand_targetlist/', data),\n",
    "#                         os.path.join('../datasets/targetlist/train/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "\n",
    "# for data in test_list:\n",
    "#     if not os.path.exists(os.path.join('../datasets/targetlist/test/', data.split('/')[0])):\n",
    "#         os.makedirs('../datasets/targetlist/test/' + data.split('/')[0], exist_ok=True)\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('/home/l/liny/ruofan/PhishIntention/src/phishpedia/expand_targetlist/', data),\n",
    "#                         os.path.join('../datasets/targetlist/test/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # for celebA\n",
    "# train_list = [x.split(' ')[0] for x in open('../datasets/celebA/list_eval_partition.txt').readlines() \\\n",
    "#                       if x.strip().split(' ')[1] == '0']\n",
    "\n",
    "# valid_list = [x.split(' ')[0] for x in open('../datasets/celebA/list_eval_partition.txt').readlines() \\\n",
    "#                       if x.strip().split(' ')[1] == '1']\n",
    "\n",
    "# test_list = [x.split(' ')[0] for x in open('../datasets/celebA/list_eval_partition.txt').readlines() \\\n",
    "#                       if x.strip().split(' ')[1] == '2']\n",
    "\n",
    "\n",
    "# os.makedirs('../datasets/celebA/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/celebA/valid', exist_ok=True)\n",
    "# os.makedirs('../datasets/celebA/test', exist_ok=True)\n",
    "\n",
    "# for data in train_list:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/celebA/img_align_celeba/img_align_celeba/', data),\n",
    "#                         os.path.join('../datasets/celebA/train/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "\n",
    "# for data in valid_list:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/celebA/img_align_celeba/img_align_celeba/', data),\n",
    "#                         os.path.join('../datasets/celebA/valid/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "\n",
    "# for data in test_list:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/celebA/img_align_celeba/img_align_celeba/', data),\n",
    "#                         os.path.join('../datasets/celebA/test/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # CIFAR100\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# traindict = unpickle('../datasets/cifar-100-python/train')\n",
    "\n",
    "# os.makedirs('../datasets/CIFAR100/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/CIFAR100/test', exist_ok=True)\n",
    "\n",
    "# for j, data in enumerate(traindict[b'data']):\n",
    "#     filename = traindict[b'filenames'][j].decode('utf-8')\n",
    "#     from PIL import Image\n",
    "#     im = Image.fromarray(np.transpose(np.reshape(data, (3,32,32)), (1,2,0)))\n",
    "#     im.save(os.path.join('../datasets/CIFAR100/train', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(traindict[b'fine_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# testdict = unpickle('../datasets/cifar-100-python/test')\n",
    "# for j, data in enumerate(testdict[b'data']):\n",
    "#     filename = testdict[b'filenames'][j].decode('utf-8')\n",
    "#     from PIL import Image\n",
    "#     im = Image.fromarray(np.transpose(np.reshape(data, (3,32,32)), (1,2,0)))\n",
    "#     im.save(os.path.join('../datasets/CIFAR100/test', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(os.listdir('../datasets/CIFAR100/test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # clothing\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('../datasets/clothing-dataset/images.csv')\n",
    "# train_imgs = list(df['image'])[:5000]\n",
    "# test_imgs = list(df['image'])[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# os.makedirs('../datasets/clothing-dataset/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/clothing-dataset/test', exist_ok=True)\n",
    "\n",
    "# for data in train_imgs:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/clothing-dataset/images', data+'.jpg'),\n",
    "#                         os.path.join('../datasets/clothing-dataset/train', data+'.jpg'))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "#     except FileNotFoundError:\n",
    "#         continue\n",
    "\n",
    "# for data in test_imgs:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/clothing-dataset/images', data+'.jpg'),\n",
    "#                         os.path.join('../datasets/clothing-dataset/test', data+'.jpg'))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "#     except FileNotFoundError:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the collate function applies random transforms to the input images\n",
    "collate_fn = data.ImageCollateFunction(input_size=32, cj_prob=0.5)\n",
    "\n",
    "# create a dataset from your image folder\n",
    "dataset = data.LightlyDataset(input_dir='../datasets/CIFAR100/train/')\n",
    "\n",
    "# build a PyTorch dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,                # pass the dataset to the dataloader\n",
    "    batch_size=128,         # a large batch size helps with the learning\n",
    "    shuffle=True,           # shuffling is important!\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False)  # apply transformations to the input images\n",
    "\n",
    "\n",
    "# create a dataset from your image folder\n",
    "dataset = data.LightlyDataset(input_dir='../datasets/CIFAR100/test/')\n",
    "\n",
    "# build a PyTorch dataloader\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,                # pass the dataset to the dataloader\n",
    "    batch_size=128,         # a large batch size helps with the learning\n",
    "    shuffle=True,           # shuffling is important!\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False)  # apply transformations to the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a resnet50 backbone\n",
    "resnet = torchvision.models.resnet.resnet50()\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# build the simsiam model\n",
    "model = models.SimSiam(resnet, num_ftrs=2048)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../output/CIFAR100.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SimSiam(\n",
       "    (backbone): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (projection_mlp): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (prediction_mlp): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:26,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "filenames = []\n",
    "\n",
    "# disable gradients for faster calculations\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (x, _, fnames) in tqdm(enumerate(test_dataloader)):\n",
    "        # move the images to the gpu\n",
    "        x = x[0].to(device)\n",
    "        # embed the images with the pre-trained backbone\n",
    "        y = model.module.backbone(x)\n",
    "        y = y.squeeze()\n",
    "        y = F.normalize(y, dim=1)\n",
    "        # store the embeddings and filenames in lists\n",
    "        embeddings.append(y)\n",
    "        filenames = filenames + list(fnames)\n",
    "\n",
    "# concatenate the embeddings and convert to numpy\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "embeddings = embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9999, 2048])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "283it [02:14,  2.70it/s]"
     ]
    }
   ],
   "source": [
    "train_embeddings = []\n",
    "train_filenames = []\n",
    "\n",
    "# disable gradients for faster calculations\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (x, _, fnames) in tqdm(enumerate(train_dataloader)):\n",
    "        # move the images to the gpu\n",
    "        x = x[0].to(device)\n",
    "        # embed the images with the pre-trained backbone\n",
    "        y = model.module.backbone(x)\n",
    "        y = y.squeeze()\n",
    "        y = F.normalize(y, dim=1)\n",
    "        # store the embeddings and filenames in lists\n",
    "        train_embeddings.append(y)\n",
    "        train_filenames = train_filenames + list(fnames)\n",
    "\n",
    "# concatenate the embeddings and convert to numpy\n",
    "train_embeddings = torch.cat(train_embeddings, dim=0)\n",
    "train_embeddings = train_embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "def knn_predict(feature: torch.Tensor,\n",
    "                feature_bank: torch.Tensor,\n",
    "                feature_labels: torch.Tensor, \n",
    "                num_classes: int,\n",
    "                knn_k: int=200,\n",
    "                knn_t: float=0.1) -> torch.Tensor:\n",
    "    \"\"\"Run kNN predictions on features based on a feature bank\n",
    "    This method is commonly used to monitor performance of self-supervised\n",
    "    learning methods.\n",
    "    The default parameters are the ones\n",
    "    used in https://arxiv.org/pdf/1805.01978v1.pdf.\n",
    "    Args:\n",
    "        feature: \n",
    "            Tensor of shape [N, D] for which you want predictions\n",
    "        feature_bank: \n",
    "            Tensor of a database of features used for kNN\n",
    "        feature_labels: \n",
    "            Labels for the features in our feature_bank\n",
    "        num_classes: \n",
    "            Number of classes (e.g. `10` for CIFAR-10)\n",
    "        knn_k: \n",
    "            Number of k neighbors used for kNN\n",
    "        knn_t: \n",
    "            Temperature parameter to reweights similarities for kNN\n",
    "    Returns:\n",
    "        A tensor containing the kNN predictions\n",
    "    Examples:\n",
    "        >>> images, targets, _ = batch\n",
    "        >>> feature = backbone(images).squeeze()\n",
    "        >>> # we recommend to normalize the features\n",
    "        >>> feature = F.normalize(feature, dim=1)\n",
    "        >>> pred_labels = knn_predict(\n",
    "        >>>     feature,\n",
    "        >>>     feature_bank,\n",
    "        >>>     targets_bank,\n",
    "        >>>     num_classes=10,\n",
    "        >>> )\n",
    "    \"\"\"\n",
    "\n",
    "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    # [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    # [B, K]\n",
    "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\n",
    "    \n",
    "    # we do a reweighting of the similarities\n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "    \n",
    "    # counts for each class\n",
    "    one_hot_label = torch.zeros(feature.size(0) * knn_k, num_classes, device=sim_labels.device)\n",
    "    \n",
    "    # [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "    # weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(one_hot_label.view(feature.size(\n",
    "        0), -1, num_classes) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# get labels for feature_bank and labels for test feature\n",
    "# df = pd.read_csv('../datasets/clothing-dataset/images.csv')\n",
    "# bank_labels = []\n",
    "# feature_labels = []\n",
    "\n",
    "# for file in filenames:\n",
    "#     label = list(df.loc[df['image'] == file.split('.jpg')[0]]['label'])[0]\n",
    "#     feature_labels.append(label)\n",
    "    \n",
    "# for file in train_filenames:\n",
    "#     label = list(df.loc[df['image'] == file.split('.jpg')[0]]['label'])[0]\n",
    "#     bank_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict = unpickle('../datasets/cifar100/test')\n",
    "feature_labels = []\n",
    "for file in tqdm(filenames):\n",
    "    index = [x.decode('utf-8') for x in testdict[b'filenames']].index(file)\n",
    "    cls = testdict[b'fine_labels'][index]\n",
    "    feature_labels.append(cls)\n",
    "\n",
    "traindict = unpickle('../datasets/cifar100/train')\n",
    "bank_labels = []\n",
    "for file in tqdm(train_filenames):\n",
    "    index = [x.decode('utf-8') for x in traindict[b'filenames']].index(file)\n",
    "    cls = traindict[b'fine_labels'][index]\n",
    "    bank_labels.append(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldict = {x:i for i, x in enumerate(set(feature_labels).union(set(bank_labels)))}\n",
    "\n",
    "feature_label_int = [labeldict[x] for x in feature_labels]\n",
    "bank_label_int = [labeldict[x] for x in bank_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_label_int = torch.tensor(feature_label_int)\n",
    "bank_label_int = torch.tensor(bank_label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "pred_labels = knn_predict(feature= embeddings,\n",
    "                          feature_bank= train_embeddings.t().contiguous(),\n",
    "                          feature_labels= bank_label_int, \n",
    "                          num_classes=len(labeldict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0045)\n"
     ]
    }
   ],
   "source": [
    "num = len(embeddings)\n",
    "top1 = (pred_labels[:, 0] == feature_label_int).float().sum()\n",
    "print(top1/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clothing dataset (4995 training, 403 testing) Test NN Acc = 0.0045\n",
    "# celebA dataset Test NN Acc = \n",
    "# CIFAR100 dataset (49999 training, 9999 testing) Test NN Acc = \n",
    "# Logo2k dataset Test NN Acc = \n",
    "# Logo targetlist dataset Test NN Acc = \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
