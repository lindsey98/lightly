{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076cc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b70252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import lightly.models as models\n",
    "import lightly.loss as loss\n",
    "import lightly.data as data\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cded2a",
   "metadata": {},
   "source": [
    "## Seperate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4802c6d9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# for logo2k and logo targetlist\n",
    "# train_list = [x.strip('\\n') for x in open('/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/train_targets.txt').readlines()]\n",
    "# test_list = [x.strip('\\n') for x in open('/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/test_targets.txt').readlines()]\n",
    "\n",
    "# os.makedirs('../datasets/targetlist/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/targetlist/test', exist_ok=True)\n",
    "\n",
    "# for data in train_list:\n",
    "#     if not os.path.exists(os.path.join('../datasets/targetlist/train/', data.split('/')[0])):\n",
    "#         os.makedirs('../datasets/targetlist/train/' + data.split('/')[0], exist_ok=True)\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('/home/l/liny/ruofan/PhishIntention/src/phishpedia/expand_targetlist/', data),\n",
    "#                         os.path.join('../datasets/targetlist/train/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "\n",
    "# for data in test_list:\n",
    "#     if not os.path.exists(os.path.join('../datasets/targetlist/test/', data.split('/')[0])):\n",
    "#         os.makedirs('../datasets/targetlist/test/' + data.split('/')[0], exist_ok=True)\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('/home/l/liny/ruofan/PhishIntention/src/phishpedia/expand_targetlist/', data),\n",
    "#                         os.path.join('../datasets/targetlist/test/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd2203c0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # for celebA\n",
    "# train_list = [x.split(' ')[0] for x in open('../datasets/celebA/list_eval_partition.txt').readlines() \\\n",
    "#                       if x.strip().split(' ')[1] == '0']\n",
    "\n",
    "# valid_list = [x.split(' ')[0] for x in open('../datasets/celebA/list_eval_partition.txt').readlines() \\\n",
    "#                       if x.strip().split(' ')[1] == '1']\n",
    "\n",
    "# test_list = [x.split(' ')[0] for x in open('../datasets/celebA/list_eval_partition.txt').readlines() \\\n",
    "#                       if x.strip().split(' ')[1] == '2']\n",
    "\n",
    "\n",
    "# os.makedirs('../datasets/celebA/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/celebA/valid', exist_ok=True)\n",
    "# os.makedirs('../datasets/celebA/test', exist_ok=True)\n",
    "\n",
    "# for data in train_list:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/celebA/img_align_celeba/img_align_celeba/', data),\n",
    "#                         os.path.join('../datasets/celebA/train/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "\n",
    "# for data in valid_list:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/celebA/img_align_celeba/img_align_celeba/', data),\n",
    "#                         os.path.join('../datasets/celebA/valid/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "\n",
    "# for data in test_list:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/celebA/img_align_celeba/img_align_celeba/', data),\n",
    "#                         os.path.join('../datasets/celebA/test/', data))\n",
    "#     except FileExistsError:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176027f2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # CIFAR100\n",
    "# def unpickle(file):\n",
    "#     import pickle\n",
    "#     with open(file, 'rb') as fo:\n",
    "#         dict = pickle.load(fo, encoding='bytes')\n",
    "#     return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31988478",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# traindict = unpickle('../datasets/cifar-100-python/train')\n",
    "\n",
    "# os.makedirs('../datasets/CIFAR100/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/CIFAR100/test', exist_ok=True)\n",
    "\n",
    "# for j, data in enumerate(traindict[b'data']):\n",
    "#     filename = traindict[b'filenames'][j].decode('utf-8')\n",
    "#     from PIL import Image\n",
    "#     im = Image.fromarray(np.transpose(np.reshape(data, (3,32,32)), (1,2,0)))\n",
    "#     im.save(os.path.join('../datasets/CIFAR100/train', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef9d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(traindict[b'fine_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d98c727",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# testdict = unpickle('../datasets/cifar-100-python/test')\n",
    "# for j, data in enumerate(testdict[b'data']):\n",
    "#     filename = testdict[b'filenames'][j].decode('utf-8')\n",
    "#     from PIL import Image\n",
    "#     im = Image.fromarray(np.transpose(np.reshape(data, (3,32,32)), (1,2,0)))\n",
    "#     im.save(os.path.join('../datasets/CIFAR100/test', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c050219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(os.listdir('../datasets/CIFAR100/test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c22e2976",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # clothing\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('../datasets/clothing-dataset/images.csv')\n",
    "# train_imgs = list(df['image'])[:5000]\n",
    "# test_imgs = list(df['image'])[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c42cfd0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# os.makedirs('../datasets/clothing-dataset/train', exist_ok=True)\n",
    "# os.makedirs('../datasets/clothing-dataset/test', exist_ok=True)\n",
    "\n",
    "# for data in train_imgs:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/clothing-dataset/images', data+'.jpg'),\n",
    "#                         os.path.join('../datasets/clothing-dataset/train', data+'.jpg'))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "#     except FileNotFoundError:\n",
    "#         continue\n",
    "\n",
    "# for data in test_imgs:\n",
    "#     try:\n",
    "#         shutil.copyfile(os.path.join('../datasets/clothing-dataset/images', data+'.jpg'),\n",
    "#                         os.path.join('../datasets/clothing-dataset/test', data+'.jpg'))\n",
    "#     except FileExistsError:\n",
    "#         continue\n",
    "#     except FileNotFoundError:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d97948",
   "metadata": {},
   "source": [
    "## Create dataloader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8e084cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the collate function applies random transforms to the input images\n",
    "collate_fn = data.ImageCollateFunction(input_size=32, cj_prob=0.5)\n",
    "\n",
    "# create a dataset from your image folder\n",
    "dataset = data.LightlyDataset(input_dir='../datasets/CIFAR100/train/')\n",
    "\n",
    "# build a PyTorch dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,                # pass the dataset to the dataloader\n",
    "    batch_size=128,         # a large batch size helps with the learning\n",
    "    shuffle=True,           # shuffling is important!\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False)  # apply transformations to the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "957c8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a resnet50 backbone\n",
    "resnet = torchvision.models.resnet.resnet50()\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# build the simsiam model\n",
    "model = models.SimSiam(resnet, num_ftrs=2048)\n",
    "\n",
    "# use a criterion for self-supervised learning\n",
    "criterion = loss.SymNegCosineSimilarityLoss()\n",
    "\n",
    "# get a PyTorch optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-0, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788c288",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "avg_loss = 0.\n",
    "avg_output_std = 0.\n",
    "epochs = 300\n",
    "out_dim = 2048\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    for (x0, x1), _, _ in dataloader:\n",
    "\n",
    "        # move images to the gpu\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "\n",
    "        # run the model on both transforms of the images\n",
    "        # the output of the simsiam model is a y containing the predictions\n",
    "        # and projections for each input x\n",
    "        y0, y1 = model(x0, x1)\n",
    "\n",
    "        # backpropagation\n",
    "        loss = criterion(y0, y1)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate the per-dimension standard deviation of the outputs\n",
    "        # we can use this later to check whether the embeddings are collapsing\n",
    "        output, _ = y0\n",
    "        output = output.detach()\n",
    "        output = torch.nn.functional.normalize(output, dim=1)\n",
    "\n",
    "        output_std = torch.std(output, 0)\n",
    "        output_std = output_std.mean()\n",
    "\n",
    "        # use moving averages to track the loss and standard deviation\n",
    "        w = 0.9\n",
    "        avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "        avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
    "\n",
    "    # the level of collapse is large if the standard deviation of the l2\n",
    "    # normalized output is much smaller than 1 / sqrt(dim)\n",
    "    collapse_level = max(0., 1 - math.sqrt(out_dim) * avg_output_std)\n",
    "    # print intermediate results\n",
    "    print(f'[Epoch {e:3d}] '\n",
    "        f'Loss = {avg_loss:.2f} | '\n",
    "        f'Collapse Level: {collapse_level:.2f} / 1.00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197499d",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68045d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "filenames = []\n",
    "\n",
    "# disable gradients for faster calculations\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (x, _, fnames) in enumerate(dataloader_test):\n",
    "        # move the images to the gpu\n",
    "        x = x.to(device)\n",
    "        # embed the images with the pre-trained backbone\n",
    "        y = model.backbone(x)\n",
    "        y = y.squeeze()\n",
    "        # store the embeddings and filenames in lists\n",
    "        embeddings.append(y)\n",
    "        filenames = filenames + list(fnames)\n",
    "\n",
    "# concatenate the embeddings and convert to numpy\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "embeddings = embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d99a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.offsetbox as osb\n",
    "from matplotlib import rcParams as rcp\n",
    "\n",
    "# for resizing images to thumbnails\n",
    "import torchvision.transforms.functional as functional\n",
    "\n",
    "# for clustering and 2d representations\n",
    "from sklearn import random_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71de59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the scatter plot we want to transform the images to a two-dimensional\n",
    "# vector space using a random Gaussian projection\n",
    "projection = random_projection.GaussianRandomProjection(n_components=2)\n",
    "embeddings_2d = projection.fit_transform(embeddings)\n",
    "\n",
    "# normalize the embeddings to fit in the [0, 1] square\n",
    "M = np.max(embeddings_2d, axis=0)\n",
    "m = np.min(embeddings_2d, axis=0)\n",
    "embeddings_2d = (embeddings_2d - m) / (M - m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scatter_plot_with_thumbnails():\n",
    "    \"\"\"Creates a scatter plot with image overlays.\n",
    "    \"\"\"\n",
    "    # initialize empty figure and add subplot\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Scatter Plot of the Sentinel-2 Dataset')\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # shuffle images and find out which images to show\n",
    "    shown_images_idx = []\n",
    "    shown_images = np.array([[1., 1.]])\n",
    "    iterator = [i for i in range(embeddings_2d.shape[0])]\n",
    "    np.random.shuffle(iterator)\n",
    "    for i in iterator:\n",
    "        # only show image if it is sufficiently far away from the others\n",
    "        dist = np.sum((embeddings_2d[i] - shown_images) ** 2, 1)\n",
    "        if np.min(dist) < 2e-3:\n",
    "            continue\n",
    "        shown_images = np.r_[shown_images, [embeddings_2d[i]]]\n",
    "        shown_images_idx.append(i)\n",
    "\n",
    "    # plot image overlays\n",
    "    for idx in shown_images_idx:\n",
    "        thumbnail_size = int(rcp['figure.figsize'][0] * 2.)\n",
    "        path = os.path.join(path_to_data, filenames[idx])\n",
    "        img = Image.open(path)\n",
    "        img = functional.resize(img, thumbnail_size)\n",
    "        img = np.array(img)\n",
    "        img_box = osb.AnnotationBbox(\n",
    "            osb.OffsetImage(img, cmap=plt.cm.gray_r),\n",
    "            embeddings_2d[idx],\n",
    "            pad=0.2,\n",
    "        )\n",
    "        ax.add_artist(img_box)\n",
    "\n",
    "    # set aspect ratio\n",
    "    ratio = 1. / ax.get_data_ratio()\n",
    "    ax.set_aspect(ratio, adjustable='box')\n",
    "\n",
    "\n",
    "# get a scatter plot with thumbnail overlays\n",
    "get_scatter_plot_with_thumbnails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a956c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = [\n",
    "    '../datasets/logo2k/train/100 Grand Bar/', # water 1\n",
    "    'S2B_MSIL1C_20200526T101559_N0209_R065_T32SLJ/tile_00527.png', # water 2\n",
    "    'S2B_MSIL1C_20200526T101559_N0209_R065_T32TNL/tile_00556.png', # land\n",
    "    'S2B_MSIL1C_20200526T101559_N0209_R065_T31SGD/tile_01731.png', # clouds 1\n",
    "    'S2B_MSIL1C_20200526T101559_N0209_R065_T32SMG/tile_00238.png', # clouds 2\n",
    "]\n",
    "\n",
    "\n",
    "def get_image_as_np_array(filename: str):\n",
    "    \"\"\"Loads the image with filename and returns it as a numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "    img = Image.open(filename)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def get_image_as_np_array_with_frame(filename: str, w: int = 5):\n",
    "    \"\"\"Returns an image as a numpy array with a black frame of width w.\n",
    "\n",
    "    \"\"\"\n",
    "    img = get_image_as_np_array(filename)\n",
    "    ny, nx, _ = img.shape\n",
    "    # create an empty image with padding for the frame\n",
    "    framed_img = np.zeros((w + ny + w, w + nx + w, 3))\n",
    "    framed_img = framed_img.astype(np.uint8)\n",
    "    # put the original image in the middle of the new one\n",
    "    framed_img[w:-w, w:-w] = img\n",
    "    return framed_img\n",
    "\n",
    "\n",
    "def plot_nearest_neighbors_3x3(example_image: str, i: int):\n",
    "    \"\"\"Plots the example image and its eight nearest neighbors.\n",
    "\n",
    "    \"\"\"\n",
    "    n_subplots = 9\n",
    "    # initialize empty figure\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(f\"Nearest Neighbor Plot {i + 1}\")\n",
    "    #\n",
    "    example_idx = filenames.index(example_image)\n",
    "    # get distances to the cluster center\n",
    "    distances = embeddings - embeddings[example_idx]\n",
    "    distances = np.power(distances, 2).sum(-1).squeeze()\n",
    "    # sort indices by distance to the center\n",
    "    nearest_neighbors = np.argsort(distances)[:n_subplots]\n",
    "    # show images\n",
    "    for plot_offset, plot_idx in enumerate(nearest_neighbors):\n",
    "        ax = fig.add_subplot(3, 3, plot_offset + 1)\n",
    "        # get the corresponding filename\n",
    "        fname = os.path.join(path_to_data, filenames[plot_idx])\n",
    "        if plot_offset == 0:\n",
    "            ax.set_title(f\"Example Image\")\n",
    "            plt.imshow(get_image_as_np_array_with_frame(fname))\n",
    "        else:\n",
    "            plt.imshow(get_image_as_np_array(fname))\n",
    "        # let's disable the axis\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# show example images for each cluster\n",
    "for i, example_image in enumerate(example_images):\n",
    "    plot_nearest_neighbors_3x3(example_image, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
